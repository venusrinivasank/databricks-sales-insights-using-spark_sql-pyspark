# databricks-sales-insights-using-spark_sql-pyspark
PySpark &amp; Spark SQL project on Databricks analyzing Superstore sales data. Features KPI metrics, customer trends, product insights, and dynamic date-based visual reporting using widgets. Ideal for exploring business intelligence and retail analytics.

### ðŸ§  Project Overview
You're analyzing Superstore sales data using Databricks, combining PySpark and Spark SQL for flexibility. Widgets allow filtering by Weekly or Monthly periods, and you're extracting insights like:

- Number of customers and orders
- Sales and profit totals
- Top-performing regions, countries, categories, and products

### Technologies Used
- Apache Spark (PySpark and Spark SQL)
- Databricks notebooks
- Python (datetime, pandas, SQL functions)

### Environment Details
- choose python as the interpretor
- choose the cluster you've created
- make sure you uploaded the correct datase
- don't forget the copy the suitable dataset file path

## Note:
- I have shared the databricks notebook I used to develop the project in .ipynb format along with raw code with readable format
